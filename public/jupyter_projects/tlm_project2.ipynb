{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4B-PufZvpEAT"
   },
   "source": [
    "# Heart Disease Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bi0GNJMBp_cR"
   },
   "source": [
    "[ML Cookbook](https://www.ml-book.com) | [SLACK Channel](https://join.slack.com/t/mlckbk/shared_invite/zt-9qsjm911-6nSHAcCSjKfuHi972iEfEg)\n",
    "\n",
    "\n",
    "## About\n",
    "In this project, you have to build a model that **predicts** (a probability of) **a heart disease of a patient**.\n",
    "\n",
    "The project contains 7 sections in total, each with step-by-step instructions of what to do. Note that, as we go further with our lessons, we will try to step away from guided projects like this to \"less-guided\", with less intructions involved. Thus, my advice is try to understand why we do what we do in what order.\n",
    "\n",
    "\n",
    "## Structure\n",
    "The project is split into **7 sections**, each containing **step-by-step instructions** of what to do. These sections are the following:\n",
    "\n",
    "1.   Import the Libratries\n",
    "2.   Import the Datasets\n",
    "3.   Data Preprocessing\n",
    "4.   Data Overview\n",
    "5.   Model Building\n",
    "6.   Model Evaluation & Hyperparameter Tuning\n",
    "7.   Conclusion\n",
    "\n",
    "## Data\n",
    "There are 2 datasets provided that you should use for this project:\n",
    "- heart1.csv\n",
    "- heart2.csv\n",
    "\n",
    "### > Columns:\n",
    "- age: age in years\n",
    "- sex: (1 = male; 0 = female)\n",
    "- cp: chest pain type\n",
    "- trestbps: resting blood pressure (in mm Hg on admission to the hospital)\n",
    "- chol: serum cholestoral in mg/dl\n",
    "- fbs: (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n",
    "- restecg: resting electrocardiographic results\n",
    "- thalach: maximum heart rate achieved\n",
    "- exang: exercise induced angina (1 = yes; 0 = no)\n",
    "- oldpeak: ST depression induced by exercise relative to rest\n",
    "- slope: the slope of the peak exercise ST segment\n",
    "- ca: number of major vessels (0-3) colored by flourosopy\n",
    "- thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n",
    "- target: 1 or 0\n",
    "\n",
    "### > Description:\n",
    "Attribute Information: \n",
    "> 1. age \n",
    "> 2. sex \n",
    "> 3. chest pain type (4 values) \n",
    "> 4. resting blood pressure \n",
    "> 5. serum cholestoral in mg/dl \n",
    "> 6. fasting blood sugar > 120 mg/dl\n",
    "> 7. resting electrocardiographic results (values 0,1,2)\n",
    "> 8. maximum heart rate achieved \n",
    "> 9. exercise induced angina \n",
    "> 10. oldpeak = ST depression induced by exercise relative to rest \n",
    "> 11. the slope of the peak exercise ST segment \n",
    "> 12. number of major vessels (0-3) colored by flourosopy \n",
    "> 13. thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n",
    "The names and social security numbers of the patients were recently removed from the database, replaced with dummy values. One file has been \"processed\", that one containing the Cleveland database. All four unprocessed files also exist in this directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N8qNIFOYrO3b"
   },
   "source": [
    "# 1. Import the Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eoxcn92XrNvk"
   },
   "source": [
    "Import the libraries needed (here you will also keep adding up the required libraries as you go further with this project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8y9j69xRpEAU"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IGScRS9srYdC"
   },
   "source": [
    "# 2. Import the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M2EbRN5hrYnC"
   },
   "source": [
    "Do the following:\n",
    "\n",
    "*   **Step 1**: Import two datasets as df1 and df2 **(we did that for you)**\n",
    "*   **Step 2**: See what the dataframes look like\n",
    "*   **Step 3**: Check the shape of each dataset by returning two lines with one print function: \n",
    "\n",
    "\n",
    "        Data shape of df1 is (X, Y),\n",
    "        Data shape of df2 is (X, Y)\n",
    "\n",
    "Use .format funtion for that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "Import two datasets as df1 and df2 **(we did that for you)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('https://raw.githubusercontent.com/the-learning-machine/data/master/tlm_project2/heart1.csv')\n",
    "df2 = pd.read_csv('https://raw.githubusercontent.com/the-learning-machine/data/master/tlm_project2/heart2.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "See what the dataframes look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "Check the shape of each dataset by returning two lines with one print function: \n",
    "\n",
    "\n",
    "        Data shape of df1 is (X, Y),\n",
    "        Data shape of df2 is (X, Y)\n",
    "\n",
    "Use .format funtion for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8kRVSK1Opfyv"
   },
   "source": [
    "# 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ufLz0XHpgBW"
   },
   "source": [
    "Do the following:\n",
    "\n",
    "\n",
    "*   **Step 1:** Combine two datasets into one\n",
    "*   **Step 2**: Check unique values of each column (function)\n",
    "*   **Step 3**: Check data types. Change if needed.\n",
    "*   **Step 4**: Create a function that checks the null values and inapropriate values (like \"?\" or \"!\") of a certain column, and if there is any, replaces them with 0 (if numeric), or 'None' (if categorical). Run the function.\n",
    "*   **Step 5**: You might have noticed that in the target column, there are values like \"Null\" and \"One\" that need to be converted into the numeric form. Write a function that will determine those cells and substitute appropriate value (either 0 or 1).\n",
    "*   **Step 6**: Validate the data: check dtypes (presence of wrong values \"?\", \"!\", null values etc), and unique values for each column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qKx2Nx7WunjR"
   },
   "source": [
    "## Step 1\n",
    "Combine two datasets into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5XB_v2TPpEAe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yumSBUj6uqfw"
   },
   "source": [
    "## Step 2\n",
    "Check unique values of each column (function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L0Y1WdJZvh7k"
   },
   "source": [
    "## Step 3\n",
    "Check data types. Change if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IvDvI232pEAm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FGBz8NaUvjql"
   },
   "source": [
    "## Step 4\n",
    "Create a function that checks the null values and inapropriate values (like \"?\" or \"!\") of a certain column, and if there is any, replaces them with 0 (if numeric), or 'None' (if categorical). Run the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5dk1O-dMpEAo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yicb8JvmvlPx"
   },
   "source": [
    "## Step 5\n",
    "You might have noticed that in the target column, there are values like \"Null\" and \"One\" that need to be converted into the numeric form. Write a function that will determine those cells and substitute appropriate value (either 0 or 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NMkNttjZvskG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6\n",
    "Validate the data: check dtypes (presence of wrong values \"?\", \"!\", null values etc), and unique values for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wdxk9oTq3ndy"
   },
   "source": [
    "# 4. Data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PQWZwzwz3qUC"
   },
   "source": [
    "Observe the data:\n",
    "\n",
    "*   **Step 1**: Find out what is the mean for **trestbps** and cholan across people with heart deseases and not. \n",
    "*   **Step 2**: Find out what is the mean for **thalach** across people with heart deseases and not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y5bSQ2_B4yuL"
   },
   "source": [
    "## Step 1\n",
    "Find out what is the mean for **trestbps** and cholan across people with heart deseases and not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3hzyVeZG4y-Z"
   },
   "source": [
    "## Step 2\n",
    "Find out what is the mean for **thalach** across people with heart deseases and not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VuyIi2SR4zGx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='model_building'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lWjSbgMsv9fv"
   },
   "source": [
    "# 5. Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uH5OXofDv_4s"
   },
   "source": [
    "Do the following:\n",
    "  \n",
    "*   **Step 1**: Identify X variables that are the most significant indicators for predicting a target. Set y variable as target category.\n",
    "*   **Step 2**: Split the data into train and test\n",
    "*   **Step 3**: Chose any classifier and train it. The function has to have some hyperparameters that you would like to have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E716ZuUc2cJV"
   },
   "source": [
    "## Step 1\n",
    "Identify X variables that are the most significant indicators for predicting a target. Set y variable as target category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ay4PMzQIpECJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uMi03wxs2eg7"
   },
   "source": [
    "## Step 2\n",
    "Split the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6cI1Jo8ixOFU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qRX8VZf82g_C"
   },
   "source": [
    "## Step 3\n",
    "Chose any classifier and train it. The function has to have some hyperparameters that you would like to have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EgL-1cWMxIpg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='hyperparameter_tuning'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Model Evaluation & Hyperparameter Tuning\n",
    "\n",
    "*   **Step 1**: Evaluate the model. Print a model score for the test data.\n",
    "*   **Step 2**: Change several hyperparameters using a loop funtion to evaluate if the score of your model can be actually improved. \n",
    "*   **Step 3**: Describe what other metrics you could potentially use to estimate model's accuracy.\n",
    "*   **Step 4**: Try to predict a probability of a heart disease by putting some values of the X variables into your classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yd_Qm_1p2iJf"
   },
   "source": [
    "## Step 1\n",
    "Evaluate the model. Print a model score for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mm6m1Wx4pECR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ejMktDi_2mEX"
   },
   "source": [
    "## Step 2\n",
    "Change several hyperparameters using a loop funtion to evaluate if the score of your model can be actually improved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iDRS9B4TpECU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "Describe what other metrics you could potentially use to estimate model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4\n",
    "Try to predict a probability of a heart disease by putting some values of the X variables into your classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d4KGlHfB49YP"
   },
   "source": [
    "# 7. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-7JZfIl95HHV"
   },
   "source": [
    "Summarize your **findings**. Did you manage to build a reliable model? What **data preprocessing** strategies and **feature selection** techniques have you used in order to get the best model? Which model has performed the best?\n",
    "\n",
    "Feel free to share/discuss your findings in our [Slack Channel](https://join.slack.com/t/mlcookbook/shared_invite/zt-eyz4czw4-l95j_2iuETCbVRPpgA3kWA)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer:\n",
    "\n",
    "'''\n",
    "\n",
    "I used X model and achieved Y accuracy...\n",
    "I believe the model is reliable as I performed X feature selection technique...\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.* Advance Zone (OPTIONAL)\n",
    "\n",
    "*This is a section intended for advanced students or those who is willing to do some additional googling in order to familiarize themselves with potentially new concepts. The steps outlined below are typically used in production data science applications, and that is why the ML-Book team thought it would be important to include it.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.1* Exploring Different Models\n",
    "\n",
    "*As you know, in data science there is no such algorithm that can outperform any other algorithms on any given dataset. Thus, model selection is typically an iterative process where we are not only searching for the optimal set of hyperparameters (as we did in [section 6, step 2](#hyperparameter_tuning)) but also exploring different machine learning algorithms as well.*\n",
    "\n",
    "*You can imagine, that for models with many parameters it can easily get very boring to specify all the values of hyperparameters that you want to check. For this and some other reasons people are using [cross-validation](https://medium.com/machine-learning-eli5/cross-validation-the-right-way-386839ed39b1).*\n",
    "\n",
    "*   **Step 1**: Train [Support Vector Machine](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) model on the train dataset. Perform any [cross-validation](https://medium.com/machine-learning-eli5/cross-validation-the-right-way-386839ed39b1) method of your choice to select an optimal values of hyperparameters *C*, *kernel* and *degree*. \n",
    "\n",
    "\n",
    "*   **Step 2**: Train [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) model on the train dataset. Perform any [cross-validation](https://medium.com/machine-learning-eli5/cross-validation-the-right-way-386839ed39b1) method of your choice to select an optimal values of hyperparameters *n_estimators* and *max_depth*.\n",
    "\n",
    "\n",
    "*   **Step 3**: Compare the performance of models built in this section as well as with the model from [section 5](#model_building). Keep in mind that it makes sense only to compare models that were trained on the same set of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "Train [Support Vector Machine](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) model on the train dataset. Perform any [cross-validation](https://medium.com/machine-learning-eli5/cross-validation-the-right-way-386839ed39b1) method of your choice to select an optimal values of hyperparameters *C*, *kernel* and *degree*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "Train [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) model on the train dataset. Perform any [cross-validation](https://medium.com/machine-learning-eli5/cross-validation-the-right-way-386839ed39b1) method of your choice to select an optimal values of hyperparameters *n_estimators* and *max_depth*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "Compare the performance of models built in this section as well as with the model from [section 5](#model_building). Keep in mind that it makes sense only to compare models that were trained on the same set of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.2* Feature Engineering\n",
    "\n",
    "*Oftentimes the relationship between our features and target variable is very complex. Thus, it can be fruitful to include some additional features based on already existing ones. In this section we will explore feature engineering for numerical columns only, but there are techniques that can be applied to categorical features as well. You can experiment with transformations that are not listed below as well!*\n",
    "\n",
    "*   **Step 1**: Generate additional univariate numerical features. Feel free to select any number of features from your dataset to apply any of these transformations.\n",
    "    *      Power of 2\n",
    "    *      Square root (watch out for negative values!)\n",
    "    *      Log transformation (can be applied only to positive values)\n",
    "\n",
    "\n",
    "*   **Step 2**: Generate additional multivariate numerical features. Feel free to select any number of features from your dataset to apply any of these transformations:\n",
    "    *      Multiplication of features' values\n",
    "    *      Ratio of features' values (watch out for zero denominator)\n",
    "    \n",
    "    \n",
    "*   **Step 3**: Generate additional categorical features. For every categorical feature from the dataset add the column with [frequency encoded values](https://python-data-science.readthedocs.io/en/latest/preprocess.html#tree-based-models).\n",
    "    \n",
    "    \n",
    "*   **Step 4**: Train any model that was described in this notebook on this extended dataset.\n",
    "\n",
    "\n",
    "*   **Step 5**: Compare the performance of the model trained on the extended dataset against the models trained on original dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "Generate additional univariate numerical features. Feel free to select any number of features from your dataset to apply any of these transformations.\n",
    "- Power of 2\n",
    "- Square root (watch out for negative values!)\n",
    "- Log transformation (can be applied only to positive values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "Generate additional multivariate numerical features. Feel free to select any number of features from your dataset to apply any of these transformations:\n",
    "- Multiplication of features' values\n",
    "- Ratio of features' values (watch out for zero denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "Generate additional categorical features. For every categorical feature from the dataset add the column with [frequency encoded values](https://python-data-science.readthedocs.io/en/latest/preprocess.html#tree-based-models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4\n",
    "Train any model that was described in this notebook on this extended dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5\n",
    "Compare the performance of the model trained on the extended dataset against the models trained on original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.3* Advanced Conclusion\n",
    "\n",
    "Take a look at all the models that you have trained in this notebook and try to answer the following questions:\n",
    "\n",
    "    Which one has performed best on a test set? \n",
    "    Why do you think this happen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer:\n",
    "\n",
    "'''\n",
    "\n",
    "I believe...\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "case_project_1.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
