{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4B-PufZvpEAT"
   },
   "source": [
    "# Fasting Blood Sugar Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bi0GNJMBp_cR"
   },
   "source": [
    "[ML Cookbook](https://www.ml-book.com) | [SLACK Channel](https://join.slack.com/t/mlckbk/shared_invite/zt-9qsjm911-6nSHAcCSjKfuHi972iEfEg)\n",
    "\n",
    "## About\n",
    "\n",
    "In this project, you have to build a model that **predicts fasting blood sugar** of a patient **is > 120 mg/dl**.\n",
    "\n",
    "The project contains 7 sections in total, each with step-by-step instructions of what to do. Note that, as we go further with our lessons, we will try to step away from guided projects like this to \"less-guided\", with less intructions involved. Thus, my advice is try to understand why we do what we do in what order.\n",
    "\n",
    "## Structure\n",
    "The project is split into **7 sections**, each containing **step-by-step instructions** of what to do. These sections are the following:\n",
    "1.   Import the Libratries\n",
    "2.   Import the Datasets\n",
    "3.   Data Preprocessing\n",
    "4.   Data Overview\n",
    "5.   Model Building\n",
    "6.   Model Evaluation & Hyperparameter Tuning\n",
    "7.   Conclusion\n",
    "\n",
    "## Data\n",
    "There are 2 datasets provided that you should use for this project:\n",
    "- fbs1.xlsx\n",
    "- fbs2.xlsx\n",
    "\n",
    "### > Columns:\n",
    "- age: age in years\n",
    "- sex: (1 = male; 0 = female)\n",
    "- cp: chest pain type\n",
    "- trestbps: resting blood pressure (in mm Hg on admission to the hospital)\n",
    "- chol: serum cholestoral in mg/dl\n",
    "- restecg: resting electrocardiographic results\n",
    "- thalach: maximum heart rate achieved\n",
    "- exang: exercise induced angina (1 = yes; 0 = no)\n",
    "- oldpeak: ST depression induced by exercise relative to rest\n",
    "- slope: the slope of the peak exercise ST segment\n",
    "- ca: number of major vessels (0-3) colored by flourosopy\n",
    "- thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n",
    "- fbs: (target - fasting blood sugar > 120 mg/dl): 1 = true; 0 = false\n",
    "\n",
    "### > Description:\n",
    "Attribute Information: \n",
    "> 1. age \n",
    "> 2. sex \n",
    "> 3. chest pain type (4 values) \n",
    "> 4. resting blood pressure \n",
    "> 5. serum cholestoral in mg/dl \n",
    "> 6. resting electrocardiographic results (values 0,1,2)\n",
    "> 7. maximum heart rate achieved \n",
    "> 8. exercise induced angina \n",
    "> 9. oldpeak = ST depression induced by exercise relative to rest \n",
    "> 10. the slope of the peak exercise ST segment \n",
    "> 11. number of major vessels (0-3) colored by flourosopy \n",
    "> 12. thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n",
    "> 13. fasting blood sugar > 120 mg/dl\n",
    "The names and social security numbers of the patients were recently removed from the database, replaced with dummy values. One file has been \"processed\", that one containing the Cleveland database. All four unprocessed files also exist in this directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N8qNIFOYrO3b"
   },
   "source": [
    "# 1. Import the Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eoxcn92XrNvk"
   },
   "source": [
    "Import the libraries needed (here you will also keep adding up the required libraries as you go further with this project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8y9j69xRpEAU"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IGScRS9srYdC"
   },
   "source": [
    "# 2. Import the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M2EbRN5hrYnC"
   },
   "source": [
    "Do the following:\n",
    "\n",
    "*   **Step 1**: Import two datasets as df1 and df2 **(we did that for you)**\n",
    "*   **Step 2**: See what the dataframes look like\n",
    "*   **Step 3**: Check the shape of each dataset by returning two lines with one print function: \n",
    "\n",
    "\n",
    "        Data shape of df1 is (X, Y),\n",
    "        Data shape of df2 is (X, Y)\n",
    "\n",
    "Use .format funtion for that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "haOdGjYXpEAY"
   },
   "source": [
    "## Step 1\n",
    "Import two datasets as df1 and df2 **(we did that for you)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel('https://raw.githubusercontent.com/the-learning-machine/data/master/tlm_project3/fbs1.xlsx')\n",
    "df2 = pd.read_excel('https://raw.githubusercontent.com/the-learning-machine/data/master/tlm_project3/fbs2.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "See what the dataframes look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "Check the shape of each dataset by returning two lines with one print function: \n",
    "\n",
    "\n",
    "        Data shape of df1 is (X, Y),\n",
    "        Data shape of df2 is (X, Y)\n",
    "\n",
    "Use .format funtion for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8kRVSK1Opfyv"
   },
   "source": [
    "# 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ufLz0XHpgBW"
   },
   "source": [
    "**Step 1:** Combine two datasets into one\n",
    "\n",
    "**Step 2**: Create a class called \"Prep\". Inside that class write functions that: \n",
    "- Prints unique values of each column\n",
    "- Prints data types\n",
    "- Replaces null values with 0.\n",
    "- Replaces inapropriate values - \"?\", \"\\\" and \"!\" of a certain column with 0.\n",
    "- Converts words \"Null\", \"One\" and \"one\" in target column into numeric form.\n",
    "\n",
    "**Step 3**: Change data types if needed.\n",
    "\n",
    "\n",
    "**Step 4**: Now, you have to preprocess id column. Something messed it up, as it should be in the form [ letter \"t\", \"l\" or \"m\" ] + [number] - e.g. \"t18\", \"l891\" or \"m142\". So how to make, for instance, \"m142\" out of \"9867r13m12e1_142\"? You should take either \"l\", \"m\", or \"t\" from that id (note that you will have multiple different letters in ids) + the number, which is digits coming after an underscore \"_\". Here are some examples of the transformation: \n",
    "- \"9867t13e12r1_92\" -> \"t92\". Even though we see two other letters in this id (\"r\" and \"e\"), the letter \"t\" should be - \"9867r13e12m1_1203\" -> \"m1203\"\n",
    "- \"343e2832j093k38042t8920402n_778\" -> \"t778\". \n",
    "\n",
    "Create a for loop that would do that. for all the cells inside the id column.\n",
    "\n",
    "**Step 5**: Validate the data: check dtypes (presence of wrong values <?, !>, null values etc), and unique values for each column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qKx2Nx7WunjR"
   },
   "source": [
    "## Step 1\n",
    "Combine two datasets into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5XB_v2TPpEAe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "Create a class called \"Prep\". Inside that class write functions that: \n",
    "- Prints unique values of each column\n",
    "- Prints data types\n",
    "- Replaces null values with 0.\n",
    "- Replaces inapropriate values - \"?\", \"\\\" and \"!\" of a certain column with 0.\n",
    "- Converts words \"Null\", \"One\" and \"one\" in target column into numeric form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yumSBUj6uqfw"
   },
   "source": [
    "## Step 3\n",
    "Change data types if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FGBz8NaUvjql"
   },
   "source": [
    "## Step 4\n",
    "Now, you have to preprocess id column. Something messed it up, as it should be in the form [ letter \"t\", \"l\" or \"m\" ] + [number] - e.g. \"t18\", \"l891\" or \"m142\". So how to make, for instance, \"m142\" out of \"9867r13m12e1_142\"? You should take either \"l\", \"m\", or \"t\" from that id (note that you will have multiple different letters in ids) + the number, which is digits coming after an underscore \"_\". Here are some examples of the transformation: \n",
    "- \"9867t13e12r1_92\" -> \"t92\". Even though we see two other letters in this id (\"r\" and \"e\"), the letter \"t\" should be - \"9867r13e12m1_1203\" -> \"m1203\"\n",
    "- \"343e2832j093k38042t8920402n_778\" -> \"t778\". \n",
    "\n",
    "Create a for loop that would do that. for all the cells inside the id column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5\n",
    "Validate the data: check dtypes (presence of wrong values <?, !>, null values etc), and unique values for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wdxk9oTq3ndy"
   },
   "source": [
    "# 4. Data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PQWZwzwz3qUC"
   },
   "source": [
    "Observe the data:\n",
    "\n",
    "*   **Step 1**: Find out what is the mean for trestbps and cholan across people with heart deseases and not. \n",
    "*   **Step 2**: Find out what is the mean for thalach across people with heart deseases and not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y5bSQ2_B4yuL"
   },
   "source": [
    "## Step 1\n",
    "Find out what is the mean for trestbps and cholan across people with heart deseases and not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3hzyVeZG4y-Z"
   },
   "source": [
    "## Step 2\n",
    "Find out what is the mean for thalach across people with heart deseases and not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VuyIi2SR4zGx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lWjSbgMsv9fv"
   },
   "source": [
    "# 5. Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uH5OXofDv_4s"
   },
   "source": [
    "Do the following:\n",
    "  \n",
    "*   **Step 1**: Identify X variables that are the most significant indicators for a price category prediction. Set y variable as price category.\n",
    "*   **Step 2**: Split the data into train and test\n",
    "*   **Step 3**: Chose any classifier. The function has to have n hyperparameters that you would like to have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E716ZuUc2cJV"
   },
   "source": [
    "## Step 1\n",
    "Identify X variables that are the most significant indicators for a price category prediction. Set y variable as price category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ay4PMzQIpECJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uMi03wxs2eg7"
   },
   "source": [
    "\n",
    "## Step 2\n",
    "Split the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6cI1Jo8ixOFU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qRX8VZf82g_C"
   },
   "source": [
    "## Step 3\n",
    "Chose any classifier. The function has to have n hyperparameters that you would like to have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EgL-1cWMxIpg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section_6'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Model Evaluation & Hyperparameter Tuning\n",
    "\n",
    "**Step 1**: Create a class \"Classifier\". Inside that class write functions that:\n",
    "\n",
    "- Builds Naive Bayes Classifier (think which one you need to build, Gaussian, Multinomial or Bernoulli) and prints the score (with all hyperparameters as parameters of the funtion).\n",
    "- Builds Decision Tree and prints the score (with all hyperparameters as parameters of the funtion). \n",
    "    - Write a loop to show how depth of the tree affects accuracy. Print out the results that (1) are lower than the difference of 0.5 between accuracy of a training and test sets, and  (2) are higher than 0.55 for test set\n",
    "    - Write a loop to show how min observations on a node, and min observations on each leaf affect accuracy. Print out the results that (1) are lower than the difference of 0.5 between accuracy of a training and test sets, and (2) are higher than 0.55 for test set\n",
    "    - Plot any accuracy curve in relation to the depth to see how it changes the score.\n",
    "    - Plot any accuracy curve in relation to the min observations on a splittable node to see how it changes the score.\n",
    "\n",
    "**Step 2**: Add the following functionality to the \"Classifier\" class that you've created above so that it also:\n",
    "- Builds Gaussian Decision Tree and prints the score (with all hyperparameters as parameters of the funtion). \n",
    "- Builds Random Forest and prints the score (with all hyperparameters as parameters of the funtion). \n",
    "- Builds Gradient Boosted Decision Tree and prints the score (with all hyperparameters as parameters of the funtion).\n",
    "    - Write a loop to show how learning rate of the tree affects accuracy. Print out the results that (1) are lower than the difference of 0.5 between accuracy of a training and test sets, and (2) are higher than 0.55 for test set\n",
    "    - Plot any accuracy curve in relation to the depth to see how it changes the score.\n",
    "\n",
    "**Step 3**: Change several hyperparameters with all tree-based classifiers using a loop and find a way to only print the score result that is higher than X.\n",
    "\n",
    "**Step 4**: Try to predict your target variable by putting some values of independent variables into your funtion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yd_Qm_1p2iJf"
   },
   "source": [
    "## Step 1\n",
    "Create a class \"Classifier\". Inside that class write functions that:\n",
    "\n",
    "- Builds Naive Bayes Classifier (think which one you need to build, Gaussian, Multinomial or Bernoulli) and prints the score (with all hyperparameters as parameters of the funtion).\n",
    "- Builds Decision Tree and prints the score (with all hyperparameters as parameters of the funtion). \n",
    "    - Write a loop to show how depth of the tree affects accuracy. Print out the results that (1) are lower than the difference of 0.5 between accuracy of a training and test sets, and  (2) are higher than 0.55 for test set\n",
    "    - Write a loop to show how min observations on a node, and min observations on each leaf affect accuracy. Print out the results that (1) are lower than the difference of 0.5 between accuracy of a training and test sets, and (2) are higher than 0.55 for test set\n",
    "    - Plot any accuracy curve in relation to the depth to see how it changes the score.\n",
    "    - Plot any accuracy curve in relation to the min observations on a splittable node to see how it changes the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ejMktDi_2mEX"
   },
   "source": [
    "## Step 2\n",
    "Add the following functionality to the \"Classifier\" class that you've created above so that it also:\n",
    "- Builds Gaussian Decision Tree and prints the score (with all hyperparameters as parameters of the funtion). \n",
    "- Builds Random Forest and prints the score (with all hyperparameters as parameters of the funtion). \n",
    "- Builds Gradient Boosted Decision Tree and prints the score (with all hyperparameters as parameters of the funtion).\n",
    "    - Write a loop to show how learning rate of the tree affects accuracy. Print out the results that (1) are lower than the difference of 0.5 between accuracy of a training and test sets, and (2) are higher than 0.55 for test set\n",
    "    - Plot any accuracy curve in relation to the depth to see how it changes the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iDRS9B4TpECU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "Change several hyperparameters with all tree-based classifiers using a loop and find a way to only print the score result that is higher than X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4\n",
    "Try to predict your target variable by putting some values of independent variables into your funtion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize your **findings**. Did you manage to build a reliable model? What **data preprocessing** strategies and **feature selection** techniques have you used in order to get the best model? Which model has performed the best?\n",
    "\n",
    "Feel free to share/discuss your findings in our [Slack Channel](https://join.slack.com/t/mlcookbook/shared_invite/zt-eyz4czw4-l95j_2iuETCbVRPpgA3kWA)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer:\n",
    "\n",
    "'''\n",
    "\n",
    "I used X model and achieved Y accuracy...\n",
    "I believe the model is reliable as I performed X feature selection technique...\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.* Advance Zone (OPTIONAL)\n",
    "\n",
    "*This is a section intended for advanced students or those who is willing to do some additional googling in order to familiarize themselves with potentially new concepts. The steps outlined below are typically used in production data science applications, and that is why the ML-Book team thought it would be important to include it.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section_8_1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.1* Feature Engineering\n",
    "\n",
    "*Oftentimes the relationship between our features and target variable is very complex. Thus, it can be fruitful to include some additional features based on already existing ones. In this section we will explore feature engineering for numerical columns only, but there are techniques that can be applied to categorical features as well. You can experiment with transformations that are not listed below as well!*\n",
    "\n",
    "*   **Step 1**: Generate additional univariate numerical features. Feel free to select any number of features from your dataset to apply any of these transformations.\n",
    "    *      Power of 2\n",
    "    *      Square root (watch out for negative values!)\n",
    "    *      Log transformation (can be applied only to positive values)\n",
    "\n",
    "\n",
    "*   **Step 2**: Generate additional multivariate numerical features. Feel free to select any number of features from your dataset to apply any of these transformations:\n",
    "    *      Multiplication of features' values\n",
    "    *      Ratio of features' values (watch out for zero denominator)\n",
    "    \n",
    "    \n",
    "*   **Step 3**: Generate additional features from categorical features. For every categorical feature from the dataset add the column with [frequency encoded values](https://python-data-science.readthedocs.io/en/latest/preprocess.html#tree-based-models).\n",
    "    \n",
    "    \n",
    "*   **Step 4**: Train any model that was described in this notebook on this extended dataset.\n",
    "\n",
    "\n",
    "*   **Step 5**: Compare the performance of the model trained on the extended dataset against the models trained on original dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "Generate additional univariate numerical features. Feel free to select any number of features from your dataset to apply any of these transformations.\n",
    "- Power of 2\n",
    "- Square root (watch out for negative values!)\n",
    "- Log transformation (can be applied only to positive values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "Generate additional multivariate numerical features. Feel free to select any number of features from your dataset to apply any of these transformations:\n",
    "- Multiplication of features' values\n",
    "- Ratio of features' values (watch out for zero denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "Generate additional features from categorical features. For every categorical feature from the dataset add the column with [frequency encoded values](https://python-data-science.readthedocs.io/en/latest/preprocess.html#tree-based-models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4\n",
    "Train any model that was described in this notebook on this extended dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5\n",
    "Compare the performance of the model trained on the extended dataset against the models trained on original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.2* CatBoost\n",
    "\n",
    "As you have probably noticed there are quite a few categorical features in our dataset. For this kind of datasets CatBoost machine learning model often results in good performance utilizing advanced categorical features encoding techniques. Furthermore, it is very convenient to use it as all those transformation happen uder-the-hood and you don't have to specify them explicitly. \n",
    "\n",
    "**Step 1**: Add the following functionality to the \"Classifier\" class from [section 6](#section_6) that you've created above so that it also builds [CatBoost Classifier](https://catboost.ai/docs/concepts/python-reference_catboostclassifier.html) \n",
    "\n",
    "**Step 2**: Pick some hyperparameters of a CatBoost model and find their optimal values using cross-validation. \n",
    "\n",
    "**Step 3**: Compare the test score of CatBoost model with other models' scores from [section 6](#section_6)\n",
    "\n",
    "**Step 4**: Compare the performance of the CatBoost model trained on the dataset that we had before completing [section 8.1*](#section_8_1) and after it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "Add the following functionality to the \"Classifier\" class from [section 6](#section_6) that you've created above so that it also builds [CatBoost Classifier](https://catboost.ai/docs/concepts/python-reference_catboostclassifier.html) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "Pick some hyperparameters of a CatBoost model and find their optimal values using cross-validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "Compare the test score of CatBoost model with other models' scores from [section 6](#section_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4\n",
    "Compare the performance of the CatBoost model trained on the dataset that we had before completing [section 8.1*](#section_8_1) and after it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "case_project_1.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
